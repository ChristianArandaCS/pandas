{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "84e5049c-c68d-4d46-8a4d-d905cbdaf693",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Order ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1796\\702693973.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Order ID'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'inner'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\panda_env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mindicator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     )\n\u001b[0;32m    121\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\panda_env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    697\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\panda_env\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1094\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\panda_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1777\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Order ID'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from datetime import datetime\n",
    "\n",
    "date = datetime.now().strftime(\"%m_%d_%Y\")\n",
    "#original format\n",
    "# df_returns_export = pd.read_csv('returns_\\\\report-1714490019067.tsv', sep=\"\\t\",encoding= 'unicode_escape')\n",
    "# df_returns_export = pd.read_csv('returns_\\\\amz_export.csv',encoding= 'unicode_escape')\n",
    "# df_order_report = pd.read_csv('returns_\\ca_export.csv')\n",
    "# df_item_export = pd.read_excel('returns_\\items_export.xlsx')\n",
    "\n",
    "#merging files\n",
    "returns_files = []\n",
    "df_returns_export = pd.DataFrame()\n",
    "\n",
    "path = 'returns_\\\\'\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=True):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".tsv\"):\n",
    "            if root.endswith(\"ab\"):\n",
    "                continue\n",
    "            else:\n",
    "                returns_files.append(pd.read_csv(os.path.join(root,file_name), sep=\"\\t\",encoding= 'unicode_escape'))\n",
    "\n",
    "for return_file in returns_files:\n",
    "\n",
    "    df_returns_export = df_returns_export.append(return_file, ignore_index=True\n",
    "    )\n",
    "\n",
    "items_files = []\n",
    "df_items_export = pd.DataFrame()\n",
    "\n",
    "path = 'returns_\\\\'\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=True):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".csv\"):\n",
    "            if root.endswith(\"ab\"):\n",
    "                continue\n",
    "            else:\n",
    "                items_files.append(pd.read_csv(os.path.join(root,file_name), encoding= 'unicode_escape'))\n",
    "\n",
    "for item_file in items_files:\n",
    "\n",
    "    df_items_export = df_items_export.append(item_file, ignore_index=True\n",
    "    )\n",
    "\n",
    "orders_files = []\n",
    "df_orders_export = pd.DataFrame()\n",
    "\n",
    "path = 'returns_\\\\'\n",
    "\n",
    "for root, directories, files in os.walk(path, topdown=True):\n",
    "    for file_name in files:\n",
    "        if file_name.endswith(\".xlsx\"):\n",
    "            if root.endswith(\"ab\"):\n",
    "                continue\n",
    "            else:\n",
    "                orders_files.append(pd.read_excel(os.path.join(root,file_name)))\n",
    "\n",
    "for order_file in orders_files:\n",
    "\n",
    "    df_orders_export = df_orders_export.append(order_file, ignore_index=True)\n",
    "\n",
    "\n",
    "def str_join(df, sep, *cols):\n",
    "    from functools import reduce\n",
    "    return reduce(lambda x, y: x.astype(str).str.cat(y.astype(str), sep=sep),[df[col] for col in cols])\n",
    "\n",
    "df_orders_export = df_orders_export.rename(columns={\"Site Order ID\": \"Order ID\"})\n",
    "df_items_export = df_items_export.rename(columns={\"Inventory Number\": \"SKU\"})\n",
    "\n",
    "inner_join = pd.merge(\n",
    "    df_returns_export,\n",
    "    df_orders_export,\n",
    "    on='Order ID',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "final_report = pd.merge(\n",
    "    inner_join,\n",
    "    df_items_export,\n",
    "    on='SKU',\n",
    "\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "final_report.groupby('Tracking ID')['Merchant SKU','UPC'].agg(' '.join).reset_index()\n",
    "final_report['full_order'] = str_join(final_report,',','Merchant SKU','UPC')\n",
    "cols = ['Tracking ID'] + [col for col in final_report if col != 'Tracking ID']\n",
    "final_report = final_report[cols].drop_duplicates(subset = ['Tracking ID'])\n",
    "final_report.to_excel(r\"C:\\Users\\sebas\\Desktop\\projects\\pandas\\returns_\" + date +\".xlsx\", index=False, encoding='utf-8',sheet_name='Report')\n",
    "\n",
    "\n",
    "# Create an new Excel file and add a worksheet.\n",
    "wb = openpyxl.load_workbook(r\"returns_\"+ date + \".xlsx\")\n",
    "\n",
    "ws2 = wb.create_sheet(title=\"Scan\")\n",
    "                                                                                                              \n",
    "scans_titles = ['Tracking Number',\t'UPC/SKU',\t'Status',\t'Order Number',\t'CA Order ID',\t'Item info']\n",
    "scans_columns = ['A','B','C','D','E','F']\n",
    "\n",
    "# write headers and excel functions\n",
    "for x in range(5):\n",
    "\n",
    "    ws2[ str(scans_columns[x]) + str(1)] = scans_titles[x]\n",
    "    if scans_titles[x] == 'Status':\n",
    "        for i in range(2,500):\n",
    "\n",
    "            ws2['C'+ str(i)] = '=IF(B'+str(i)+'=\"\",\"\",IF(ISNUMBER(SEARCH(B'+str(i)+',F'+str(i)+'))= FALSE,\"WRONG RETURN\",\"\"))'\n",
    "    elif scans_titles[x] =='Order Number':\n",
    "        for i in range(2,500):\n",
    "            ws2['E'+str(i)] = '=IFERROR(VLOOKUP(A' +str(i)+ ',Report!A:F,2,FALSE),\"\")'\n",
    "    elif scans_titles[x] =='CA Order ID':\n",
    "        for i in range(2,500):\n",
    "            ws2['F'+str(i)] = '=IFERROR(VLOOKUP(A'+str(i)+',Report!A:F,4,FALSE),\"\")'\n",
    "    elif scans_titles[x] =='Item info':\n",
    "        for i in range(2,500):\n",
    "            ws2['G'+str(i)] = '=IF(A'+str(i) + '=\"\",\"\",VLOOKUP(A'+str(i)+',Report!A:G,7,FALSE))'\n",
    "\n",
    "# ws2.protection.sheet = True\n",
    "\n",
    "# for col in ['A','B','C','E','F','G']:\n",
    "#     for cell in ws2[col]:\n",
    "#         cell.protection = WorkbookProtection(locked=False)\n",
    "\n",
    "wb.save(\"returns_\"+date+\".xlsx\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
